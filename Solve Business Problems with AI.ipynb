{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f07594f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from helper import get_openai_api_key\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8d549b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4.1-nano\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "TOP_K = 5\n",
    "openai_api_key = get_openai_api_key()\n",
    "client = OpenAI(api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c9548c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_chat_model(system_prompt, user_prompt, model=MODEL, max_tokens=400):\n",
    "    \"\"\"\n",
    "    Single-call wrapper to OpenAI chat completion (chat/completions style).\n",
    "    Relies on a global `client` and default `MODEL`.\n",
    "    \"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4d58e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into chunks of specified size with overlap.\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_len = len(text)\n",
    "    while start < text_len:\n",
    "        end = min(start + chunk_size, text_len)\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        if end == text_len:\n",
    "            break\n",
    "        start = end - overlap  # step forward with overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5caa348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- EMBEDDING / INDEX BUILD ----------\n",
    "def embed_texts(texts, model=EMBEDDING_MODEL, batch_size=8, sleep_between=0.2):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of texts. Uses batching to be gentle on the API.\n",
    "    Returns list of vectors (numpy arrays).\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        resp = client.embeddings.create(model=model, input=batch)\n",
    "        for item in resp.data:\n",
    "            vec = np.array(item.embedding, dtype=np.float32)\n",
    "            embeddings.append(vec)\n",
    "        time.sleep(sleep_between)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c6a15809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Anygle cosine similarity between two vectors. Used for RAG retrieval.\"\"\"\n",
    "    if a.ndim == 1:\n",
    "        a = a.reshape(1, -1)\n",
    "    if b.ndim == 1:\n",
    "        b = b.reshape(1, -1)\n",
    "    num = (a * b).sum()\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return float(num / denom) if denom else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a872c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_from_df(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build an in-memory index of product chunks.\n",
    "    Only indexing these columns: product_id, name, category, description, seasons, price.\n",
    "    (Stock is deliberately excluded so that stock changes don’t require a re-embed.)\n",
    "\n",
    "    Returns: list of dicts: {\"embedding\": ..., \"row_idx\": int, \"chunk\": str}\n",
    "    \"\"\"\n",
    "\n",
    "    cols = [c for c in [\"product_id\", \"name\", \"category\", \"description\", \"seasons\", \"price\"] if c in df.columns]\n",
    "    safe_df = df[cols].copy()\n",
    "\n",
    "    row_chunks = [] \n",
    "    for idx, row in safe_df.iterrows():\n",
    "        combined = (\n",
    "            f\"product_id: {row.get('product_id', '')}\\n\"\n",
    "            f\"name: {row.get('name', '')}\\n\"\n",
    "            f\"category: {row.get('category', '')}\\n\"\n",
    "            f\"description: {row.get('description', '')}\\n\"\n",
    "            f\"seasons: {row.get('seasons', '')}\\n\"\n",
    "            f\"price: {row.get('price', '')}\"\n",
    "        )\n",
    "        for c in chunk_text(combined):\n",
    "            row_chunks.append((idx, c))\n",
    "\n",
    "    texts = [c for (_, c) in row_chunks]\n",
    "    embeddings = embed_texts(texts) if texts else []\n",
    "    index = []\n",
    "    for emb, (row_idx, chunk_text_) in zip(embeddings, row_chunks):\n",
    "        index.append({\"embedding\": emb, \"row_idx\": row_idx, \"chunk\": chunk_text_})\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e4f72506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(query: str, index: List[Dict[str, Any]], top_k: int = TOP_K) -> Tuple[List[Tuple[float, Dict[str, Any]]], List[int]]:\n",
    "    \"\"\"Retrieve top-k chunks using cosine similarity\"\"\"\n",
    "    if not query or not index:\n",
    "        return [], []\n",
    "    q_emb = embed_texts([query])[0]\n",
    "    q_emb = np.array(q_emb)\n",
    "    scored = []\n",
    "    for item in index:\n",
    "        sim = cosine_similarity(q_emb, np.array(item[\"embedding\"]))\n",
    "        scored.append((sim, item))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    top = scored[:top_k]\n",
    "    row_idxs = [item[\"row_idx\"] for (_, item) in top]\n",
    "    return top, row_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "601e320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_prompt(query: str, retrieved: List[Tuple[float, Dict[str, Any]]]) -> str:\n",
    "    \"\"\"\n",
    "    Building a system+user prompt where we provide retrieved context and ask the LLM to answer.\n",
    "    \"\"\"\n",
    "    context_blocks = []\n",
    "    for score, item in retrieved:\n",
    "        context_blocks.append(f\"[score={score:.3f}]\\n{item['chunk']}\")\n",
    "    context_text = \"\\n\\n\".join(context_blocks) if context_blocks else \"\"\n",
    "    user_prompt = (\n",
    "        \"You will be provided an user enquiry regarding products. Use ONLY the context below and do not assume anything.\\n\"\n",
    "        \"If the question is unrelated to the context, say that you don’t have enough info.\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context_text}\\n\\n\"\n",
    "        f\"QUESTION:\\n{query}\\n\"\n",
    "    )\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e4265904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_classify_email(client, model: str, email: Dict[str, str]) -> str:\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an email intent classifier. Choose EXACTLY ONE label:\\n\"\n",
    "        \"• order request  – the sender intends to buy/place an order OR asks concrete purchasing details \"\n",
    "        \"(price, quantity, availability/stock, lead time, shipping) with intent to proceed.\\n\"\n",
    "        \"• product inquiry – general questions (features, specs, comparisons, suitability) without intent to purchase now.\\n\"\n",
    "        \"Return ONLY the label text: 'order request' or 'product inquiry'. No punctuation, no JSON.\"\n",
    "    )\n",
    "    user_prompt = (\n",
    "        f\"EMAIL_ID: {email.get('email_id','')}\\n\"\n",
    "        f\"SUBJECT: {email.get('subject','')}\\n\"\n",
    "        f\"MESSAGE: {email.get('message','')}\\n\\n\"\n",
    "        \"Answer with exactly one label.\"\n",
    "    )\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    text = (resp.choices[0].message.content or \"\").strip().lower()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9eb0ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_extract_order_items(client, model: str, email: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Ask the LLM to extract product requests and quantities from a single order email.\n",
    "    Returns list of dicts with EXACT keys:\n",
    "      - product_id: string SKU/ID if explicitly present in the email, else null\n",
    "      - product_name: human-readable name/descriptor from the email (non-empty string)\n",
    "      - quantity: number of order integer >= 1 (default to 1 if unclear)\n",
    "      - raw_text: exact substring copied from the email that mentions the item/quantity\n",
    "    \"\"\"\n",
    "    import json\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a precise information extractor. Return ONLY a valid JSON array. \"\n",
    "        \"Each array element is an object with EXACTLY these keys in any order: \"\n",
    "        \"product_id, product_name, quantity, raw_text. \"\n",
    "        \"Rules:\\n\"\n",
    "        \"- product_id: the exact SKU/ID if explicitly present in the email; otherwise null.\\n\"\n",
    "        \"- product_name: concise name/descriptor from the email (must be a non-empty string).\\n\"\n",
    "        \"- quantity: integer >= 1. Default to 1 if not clearly stated. Convert words like 'two' -> 2.\\n\"\n",
    "        \"- raw_text: copy the exact snippet from the email that mentions the item/quantity.\\n\"\n",
    "        \"Do NOT include extra keys. Do NOT include explanations, markdown, or code fences. \"\n",
    "        \"If no items are found, return an empty JSON array [].\"\n",
    "    )\n",
    "\n",
    "    user_prompt = (\n",
    "        \"Extract product order lines from the following customer email.\\n\\n\"\n",
    "        f\"EMAIL_ID: {email.get('email_id','')}\\n\"\n",
    "        f\"SUBJECT: {email.get('subject','')}\\n\"\n",
    "        f\"MESSAGE:\\n{email.get('message','')}\\n\\n\"\n",
    "        \"Return ONLY the JSON array.\"\n",
    "    )\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    text = (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "    print(f\"LLM response for order items extraction from email_id={email.get('email_id','')}:\\n{text}\\n\")\n",
    "\n",
    "    try:\n",
    "        items = json.loads(text)\n",
    "        print(f\"Extracted items from email_id={email.get('email_id','')}: {items}\")\n",
    "        return items if isinstance(items, list) else []\n",
    "    except Exception:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6820b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_generate_order_response(client, model: str, email_id: str, order_lines: List[Dict[str,Any]], products: pd.DataFrame) -> str:\n",
    "    \"\"\"Given processed order lines with status, ask LLM to craft a professional response email.\n",
    "    order_lines: list of dicts with keys: product_id, product_name, requested_qty, status, allocated_qty(optional)\n",
    "    \"\"\"\n",
    "    lines_summary = []\n",
    "    for l in order_lines:\n",
    "        pid = l.get('product_id') or l.get('product_name')\n",
    "        status = l.get('status')\n",
    "        rq = l.get('requested_qty')\n",
    "        aq = l.get('allocated_qty', 0)\n",
    "        pname = l.get('product_name')\n",
    "\n",
    "        if status == 'created':\n",
    "            lines_summary.append(f\"{pname}: {aq} of {rq} — confirmed\")\n",
    "        elif status == 'out of stock':\n",
    "            lines_summary.append(f\"{pname}: requested {rq} — out of stock\")\n",
    "        else:\n",
    "            lines_summary.append(f\"{pname}: requested {rq} — status: {status}\")\n",
    "    summary_text = \"\\n\".join(lines_summary)\n",
    "\n",
    "    print(f\"Order summary for email_id={email_id}:\\n{summary_text}\\n\")\n",
    "\n",
    "    prompt = (\n",
    "        f\"Write a professional customer-facing email in reply to order {email_id}. Use a concise, helpful tone.\\n\"\n",
    "        f\"Order summary:\\n{summary_text}\\n\\n\"\n",
    "        \"Properly format the email with subject greeting and signature.\"\n",
    "        \"if atleast one order is confirmed then Subject should be 'Order for Product Name(s) - Confirmed'. in body Mention that the order has been received and and confirmed and customer will be notified once shipped.\"\n",
    "        \"if all are out of stock then Subject should be 'COrder for Product Name(s) - Out of stock'. In body mention that the order cannot be placed due to unavailability of stock.\"\n",
    "        \"Greet with Dear Customer, in the body thank the customer, then provide the update, and end with 'Best regards \\n Dibyendu from ShopOnline' .\"\n",
    "        \"Tell them to reach out for any questions.\"\n",
    "        \"adapt tone appropriately based on the context of the customer's request\"\n",
    "        \n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    print(f\"Generated order response for email_id={email_id}\")\n",
    "    return resp.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ef1ee32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_order_requests_pipeline(client, model: str, emails_df: pd.DataFrame, classification_df: pd.DataFrame, products_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Process a single email labeled as 'order request'. Returns (order_status_df, order_response_df).\"\"\"\n",
    "    order_status_rows: List[Dict[str, Any]] = []\n",
    "    order_responses: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Expect a single email row; merge to confirm it's an order request\n",
    "    merged = emails_df.merge(classification_df, on='email_id', how='inner')\n",
    "    if merged.empty or str(merged.iloc[0].get('category', '')).lower() != 'order request':\n",
    "        # Nothing to do for non-order emails\n",
    "        return (\n",
    "            pd.DataFrame(columns=['email_id','product_id','quantity','status']),\n",
    "            pd.DataFrame(columns=['email_id','response'])\n",
    "        )\n",
    "\n",
    "    email = merged.iloc[0].to_dict()\n",
    "\n",
    "    # Extract items from this one email\n",
    "    items = llm_extract_order_items(client, model, email)\n",
    "    print(f\"Extracted items from email_id={email.get('email_id','')}: {items}\")\n",
    "    processed_lines = []\n",
    "\n",
    "    for it in (items or []):\n",
    "        pid = it.get('product_id')\n",
    "        pname = it.get('product_name')\n",
    "        qty = int(it.get('quantity', 1) or 1)\n",
    "        allocated = 0\n",
    "        status = 'out of stock'\n",
    "\n",
    "        # Try product_id exact match first\n",
    "        if pid and 'product_id' in products_df.columns:\n",
    "            prod_idx = products_df[products_df['product_id'] == pid]\n",
    "            if not prod_idx.empty:\n",
    "                stock = int(prod_idx.iloc[0].get('stock', 0) or 0)\n",
    "                if stock >= qty:\n",
    "                    allocated = qty\n",
    "                    status = 'created'\n",
    "                    products_df.loc[products_df['product_id'] == pid, 'stock'] = stock - qty\n",
    "                elif stock > 0:\n",
    "                    allocated = stock\n",
    "                    status = 'out of stock'\n",
    "                    products_df.loc[products_df['product_id'] == pid, 'stock'] = 0\n",
    "\n",
    "        # Fallback by exact name match (case-insensitive)\n",
    "        if allocated == 0 and pname and 'name' in products_df.columns:\n",
    "            prod_idx = products_df[products_df['name'].str.lower() == str(pname).lower()]\n",
    "            if not prod_idx.empty:\n",
    "                pid = prod_idx.iloc[0].get('product_id', pid)\n",
    "                stock = int(prod_idx.iloc[0].get('stock', 0) or 0)\n",
    "                if stock >= qty:\n",
    "                    allocated = qty\n",
    "                    status = 'created'\n",
    "                    products_df.loc[products_df['name'].str.lower() == str(pname).lower(), 'stock'] = stock - qty\n",
    "                elif stock > 0:\n",
    "                    allocated = stock\n",
    "                    status = 'out of stock'\n",
    "                    products_df.loc[products_df['name'].str.lower() == str(pname).lower(), 'stock'] = 0\n",
    "\n",
    "        processed_lines.append({\n",
    "            'product_id': pid,\n",
    "            'product_name': pname,\n",
    "            'requested_qty': qty,\n",
    "            'allocated_qty': allocated,\n",
    "            'status': status,\n",
    "        })\n",
    "\n",
    "        order_status_rows.append({\n",
    "            'email_id': email.get('email_id'),\n",
    "            'product_id': pid,\n",
    "            'quantity': qty,\n",
    "            'status': 'created' if allocated == qty and qty > 0 else 'out of stock',\n",
    "        })\n",
    "\n",
    "    # Generate a customer-facing response for this email (even if no items parsed)\n",
    "    response_text = llm_generate_order_response(client, model, email.get('email_id'), processed_lines, products_df)\n",
    "    order_responses.append({'email_id': email.get('email_id'), 'response': response_text})\n",
    "\n",
    "    order_status_df = pd.DataFrame(order_status_rows, columns=['email_id','product_id','quantity','status']) if order_status_rows else pd.DataFrame(columns=['email_id','product_id','quantity','status'])\n",
    "    order_response_df = pd.DataFrame(order_responses, columns=['email_id','response'])\n",
    "    return order_status_df, order_response_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "078c9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_write_stock_df_query(client, model: str, email: Dict[str, str], product_inventory: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract product_id(s) from the inquiry and RETURN the current stock details directly.\n",
    "\n",
    "    Returns:\n",
    "      {\n",
    "        \"product_ids\": [..],\n",
    "        \"stock_details\": [{\"product_id\": \"<id>\", \"stock\": <int>}, ...]\n",
    "      }\n",
    "    \"\"\"\n",
    "    import json, re\n",
    "\n",
    "    prompt = (\n",
    "        \"Read the following customer inquiry and extract any product_id values mentioned.\\n\"\n",
    "        \"Return ONLY JSON with key 'product_ids' (array of strings). No explanation.\\n\\n\"\n",
    "        f\"EMAIL_ID: {email.get('email_id','')}\\n\"\n",
    "        f\"SUBJECT: {email.get('subject','')}\\n\"\n",
    "        f\"MESSAGE: {email.get('message','')}\\n\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    text = resp.choices[0].message.content\n",
    "    out = {\"product_ids\": [], \"stock_details\": []}\n",
    "\n",
    "    # Parse product_ids from model output\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        if isinstance(data, dict):\n",
    "            pids = data.get(\"product_ids\") or []\n",
    "            out[\"product_ids\"] = [str(x) for x in pids if isinstance(x, (str, int))]\n",
    "    except Exception:\n",
    "        # If not valid JSON, try to scrape IDs that look like tokens with letters+digits/underscores\n",
    "        # (kept minimal; you said no fallback classification logic, this is only for ID parsing if JSON slips)\n",
    "        ids = re.findall(r\"\\b[A-Za-z0-9_-]{3,}\\b\", text or \"\")\n",
    "        out[\"product_ids\"] = ids\n",
    "\n",
    "    # Build stock_details directly from the provided inventory\n",
    "    if (\n",
    "        isinstance(product_inventory, pd.DataFrame)\n",
    "        and \"product_id\" in product_inventory.columns\n",
    "        and \"stock\" in product_inventory.columns\n",
    "        and out[\"product_ids\"]\n",
    "    ):\n",
    "        sub = product_inventory.loc[\n",
    "            product_inventory[\"product_id\"].isin(out[\"product_ids\"]),\n",
    "            [\"product_id\", \"stock\"],\n",
    "        ].copy()\n",
    "        out[\"stock_details\"] = [\n",
    "            {\"product_id\": str(r.product_id), \"stock\": int(r.stock) if pd.notnull(r.stock) else 0}\n",
    "            for _, r in sub.iterrows()\n",
    "        ]\n",
    "\n",
    "    print(\n",
    "        f\"Extracted product_ids {out['product_ids']} from email_id={email.get('email_id','')}; \"\n",
    "        f\"stock_details={out['stock_details']}\"\n",
    "    )\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0afb2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_inquiry_with_stock(\n",
    "    client,\n",
    "    model: str,\n",
    "    products_df: pd.DataFrame,\n",
    "    product_inventory: pd.DataFrame,\n",
    "    email: Dict[str, str],\n",
    "    top_k: int = TOP_K,\n",
    ") -> str:\n",
    "    # RAG retrieval from index\n",
    "    query_txt = email.get(\"message\") or email.get(\"subject\") or \"\"\n",
    "    retrieved, _ = search_index(query_txt, INDEX, top_k=top_k)\n",
    "\n",
    "    # Extract product_ids and get live stock details directly\n",
    "    stock_spec = llm_write_stock_df_query(client, model, email, product_inventory)\n",
    "    stock_details = stock_spec.get(\"stock_details\") or []\n",
    "\n",
    "    # Build final prompt\n",
    "    ctx_blocks = []\n",
    "    for score, item in retrieved:\n",
    "        ctx_blocks.append(f\"[score={score:.3f}]\\n{item['chunk']}\")\n",
    "    ctx_text = \"\\n\\n\".join(ctx_blocks) if ctx_blocks else \"\"\n",
    "\n",
    "    stock_text = (\n",
    "        \"\\n\".join(f\"{d.get('product_id')}: stock={int(d.get('stock', 0))}\" for d in stock_details)\n",
    "        if stock_details\n",
    "        else \"(no specific stock ids found)\"\n",
    "    )\n",
    "\n",
    "    system_prompt = \"You are a helpful product support assistant. Be precise and do not invent details.\"\n",
    "    user_prompt = (\n",
    "        \"Use the product CONTEXT retrieved from Catalogue and the live STOCK info to write an reply email to the customer inquiry.\\n\"\n",
    "        \"Properly format the email with subject greeting body and signature.\"\n",
    "        \"Start with Dear Customer, and end with Best regards 'Dibyendu from ShopOnline' .\"\n",
    "        \"If you lack stock info for an item they asked about, and if the customer has not explicitly asked for it, do not mention anything about stock. If it's available only then mention that it is available in stock. Do not quote how many stock you have, just mention available\\n\"\n",
    "        \"adapt tone appropriately based on the context of the customer's inquiry.\\n\"\n",
    "        f\"CONTEXT (retrieved RAG chunks):\\n{ctx_text}\\n\\n\"\n",
    "        f\"STOCK (current by product_id):\\n{stock_text}\\n\\n\"\n",
    "        f\"CUSTOMER EMAIL:\\nID: {email.get('email_id','')}\\nSUBJECT: {email.get('subject','')}\\nMESSAGE: {email.get('message','')}\\n\"\n",
    "    )\n",
    "    print(f\"Answering inquiry for email_id={email.get('email_id','')}\")\n",
    "    return call_chat_model(system_prompt, user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2ecaf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emails_one_by_one(client, model: str, emails_df: pd.DataFrame, products_df: pd.DataFrame,\n",
    "                              index_df: pd.DataFrame = None,\n",
    "                              save_paths: Dict[str,str] = None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process emails sequentially.\n",
    "\n",
    "    Flow per email:\n",
    "      1) llm_classify_email -> append to email-classification\n",
    "      2) if 'order request':\n",
    "            llm_extract_order_items -> process_order_requests_pipeline (updates inventory & order-status)\n",
    "            -> llm_generate_order_response (append to order-response)\n",
    "         else 'product inquiry':\n",
    "            answer_inquiry_with_stock (RAG + stock by product_id) -> append to inquiry-response\n",
    "\n",
    "    At the end: saves CSVs if `save_paths` provided.\n",
    "\n",
    "    Returns: (product_inventory, classification_df, order_status_df, order_response_df, inquiry_response_df)\n",
    "    \"\"\"\n",
    "    # Copy of products_df as product_inventory (mutable)\n",
    "    product_inventory = products_df.copy(deep=True)\n",
    "\n",
    "    # Build / reuse index (on allowed columns only)\n",
    "    global INDEX\n",
    "    base_for_index = index_df if index_df is not None else product_inventory\n",
    "    INDEX = build_index_from_df(base_for_index)\n",
    "\n",
    "    classification_rows: List[Dict[str, Any]] = []\n",
    "    order_status_all: List[pd.DataFrame] = []\n",
    "    order_response_rows: List[Dict[str, Any]] = []\n",
    "    inquiry_response_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Process one-by-one\n",
    "    for _, row in emails_df.iterrows():\n",
    "        email = row.to_dict()\n",
    "        category = llm_classify_email(client, model, email)\n",
    "        classification_rows.append({'email_id': email.get('email_id'), 'category': category})\n",
    "\n",
    "        if category == 'order request':\n",
    "            # Build a temp classification_df for the single email to reuse your existing pipeline\n",
    "            tmp_class_df = pd.DataFrame([{'email_id': email.get('email_id'), 'category': 'order request'}])\n",
    "            # Use the kept pipeline against the single email row\n",
    "            single_email_df = pd.DataFrame([email])\n",
    "            order_status_df, order_response_df = process_order_requests_pipeline(\n",
    "                client, model, single_email_df, tmp_class_df, product_inventory\n",
    "            )\n",
    "            if not order_status_df.empty:\n",
    "                order_status_all.append(order_status_df)\n",
    "            if not order_response_df.empty:\n",
    "                order_response_rows.extend(order_response_df.to_dict('records'))\n",
    "\n",
    "        else:  # product inquiry\n",
    "            response_text = answer_inquiry_with_stock(client, model, products_df, product_inventory, email)\n",
    "            inquiry_response_rows.append({'email_id': email.get('email_id'), 'response': response_text})\n",
    "\n",
    "    # Final DataFrames with required schemas\n",
    "    classification_df = pd.DataFrame(classification_rows, columns=['email_id','category']) if classification_rows else pd.DataFrame(columns=['email_id','category'])\n",
    "    order_status_df = pd.concat(order_status_all, ignore_index=True) if order_status_all else pd.DataFrame(columns=['email_id','product_id','quantity','status'])\n",
    "    order_response_df = pd.DataFrame(order_response_rows, columns=['email_id','response']) if order_response_rows else pd.DataFrame(columns=['email_id','response'])\n",
    "    inquiry_response_df = pd.DataFrame(inquiry_response_rows, columns=['email_id','response']) if inquiry_response_rows else pd.DataFrame(columns=['email_id','response'])\n",
    "\n",
    "    # Save CSVs if requested\n",
    "    if save_paths:\n",
    "        if save_paths.get('classification'):\n",
    "            classification_df.to_csv(save_paths['classification'], index=False)\n",
    "        if save_paths.get('order_status'):\n",
    "            order_status_df.to_csv(save_paths['order_status'], index=False)\n",
    "        if save_paths.get('order_response'):\n",
    "            order_response_df.to_csv(save_paths['order_response'], index=False)\n",
    "        if save_paths.get('inquiry_response'):\n",
    "            inquiry_response_df.to_csv(save_paths['inquiry_response'], index=False)\n",
    "\n",
    "    return product_inventory, classification_df, order_status_df, order_response_df, inquiry_response_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f305c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SAVE_PATHS = {\n",
    "    'classification': 'email-classification.csv',\n",
    "    'order_status': 'order-status.csv',\n",
    "    'order_response': 'order-response.csv',\n",
    "    'inquiry_response': 'inquiry-response.csv',\n",
    "    'udated_inventory': 'product_inventory.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3684d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv('products.csv')\n",
    "emails_df = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5659610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response for order items extraction from email_id=E001:\n",
      "[\n",
      "  {\n",
      "    \"product_id\": \"LTH0976\",\n",
      "    \"product_name\": \"Leather Bifold Wallets\",\n",
      "    \"quantity\": 1,\n",
      "    \"raw_text\": \"all the remaining LTH0976 Leather Bifold Wallets you have in stock\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Extracted items from email_id=E001: [{'product_id': 'LTH0976', 'product_name': 'Leather Bifold Wallets', 'quantity': 1, 'raw_text': 'all the remaining LTH0976 Leather Bifold Wallets you have in stock'}]\n",
      "Extracted items from email_id=E001: [{'product_id': 'LTH0976', 'product_name': 'Leather Bifold Wallets', 'quantity': 1, 'raw_text': 'all the remaining LTH0976 Leather Bifold Wallets you have in stock'}]\n",
      "Order summary for email_id=E001:\n",
      "Leather Bifold Wallets: 1 of 1 — confirmed\n",
      "\n",
      "Generated order response for email_id=E001\n",
      "LLM response for order items extraction from email_id=E002:\n",
      "[\n",
      "  {\n",
      "    \"product_id\": \"VBT2345\",\n",
      "    \"product_name\": \"Vibrant Tote bag\",\n",
      "    \"quantity\": 1,\n",
      "    \"raw_text\": \"buy the VBT2345 Vibrant Tote bag\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Extracted items from email_id=E002: [{'product_id': 'VBT2345', 'product_name': 'Vibrant Tote bag', 'quantity': 1, 'raw_text': 'buy the VBT2345 Vibrant Tote bag'}]\n",
      "Extracted items from email_id=E002: [{'product_id': 'VBT2345', 'product_name': 'Vibrant Tote bag', 'quantity': 1, 'raw_text': 'buy the VBT2345 Vibrant Tote bag'}]\n",
      "Order summary for email_id=E002:\n",
      "Vibrant Tote bag: 1 of 1 — confirmed\n",
      "\n",
      "Generated order response for email_id=E002\n",
      "Extracted product_ids [] from email_id=E003; stock_details=[]\n",
      "Answering inquiry for email_id=E003\n",
      "LLM response for order items extraction from email_id=E004:\n",
      "[\n",
      "  {\n",
      "    \"product_id\": \"SFT1098\",\n",
      "    \"product_name\": \"Infinity Scarves\",\n",
      "    \"quantity\": 4,\n",
      "    \"raw_text\": \"three to four SFT1098 Infinity Scarves\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Extracted items from email_id=E004: [{'product_id': 'SFT1098', 'product_name': 'Infinity Scarves', 'quantity': 4, 'raw_text': 'three to four SFT1098 Infinity Scarves'}]\n",
      "Extracted items from email_id=E004: [{'product_id': 'SFT1098', 'product_name': 'Infinity Scarves', 'quantity': 4, 'raw_text': 'three to four SFT1098 Infinity Scarves'}]\n",
      "Order summary for email_id=E004:\n",
      "Infinity Scarves: 4 of 4 — confirmed\n",
      "\n",
      "Generated order response for email_id=E004\n",
      "Extracted product_ids ['CSH1098'] from email_id=E005; stock_details=[{'product_id': 'CSH1098', 'stock': 3}]\n",
      "Answering inquiry for email_id=E005\n"
     ]
    }
   ],
   "source": [
    "product_inventory, classification_df, order_status_df, order_response_df, inquiry_response_df = process_emails_one_by_one(\n",
    "    client=client,\n",
    "    model=MODEL,\n",
    "    emails_df=emails_df.head(5),\n",
    "    products_df=products_df,   # copied internally to product_inventory\n",
    "    index_df=None,             # optional: pass a curated df for building the RAG index\n",
    "    save_paths=DEFAULT_SAVE_PATHS      # writes the CSVs at the end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d690d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
